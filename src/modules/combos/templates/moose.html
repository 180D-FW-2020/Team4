<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <title>BruinDoodle.io Speech and Video</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
      #container {
        margin: 0px auto;
        width: 500px;
        height: 375px;
        border: 10px #333 solid;
      }
      #videoElement {
        width: 500px;
        height: 375px;
        background-color: #666;
      }
      </style>
  </head>
  <body>
    <h1>Speech and Video demo</h1>

    <div id="controls">
     <button id="recordButton">Record</button>
     <button id="pauseButton" disabled>Pause</button>
     <button id="stopButton" disabled>Stop</button>
    </div>
    <div class="control"><button id="startAndStop" disabled>Start</button></div>
    <div id="formats">Format: start recording to see sample rate</div>
    <!-- <p><strong>Recordings:</strong></p>-->
    <ol id="recordingsList"></ol>
    <!-- inserting these scripts at the end to be able to use all the elements in the DOM -->
    <!--<img id="bg" src="{{ url_for('video_feed') }}">-->
    <div id="container">
      <video autoplay="true" id="videoElement">
      </video>
    </div>
    <div id="container">
      <canvas id="canvasOutput" width="320" height="240" ></canvas>
    </div>
    <script src="/static/js/recorder.js"></script> 
    <script src="/static/js/app.js"></script>
    <script src="/static/js/opencv.js"></script>
    <script src="/static/js/socket.io.js"></script>
    <script src="/static/js/utils.js" type="text/javascript"></script>
    <!--<script src="/static/js/camera.js"></script>-->
    <script type="text/javascript">
      let video = document.getElementById('videoInput');
      let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
      let cap = new cv.VideoCapture(video);
      
      const FPS = 30;
      function processVideo() {
          try {
              if (!streaming) {
                  // clean and stop.
                  src.delete();
                  dst.delete();
                  return;
              }
              let begin = Date.now();
              // start processing.
              cap.read(src);
              cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
              cv.imshow('canvasOutput', dst);
              // schedule the next one.
              let delay = 1000/FPS - (Date.now() - begin);
              setTimeout(processVideo, delay);
          } catch (err) {
              console.log(err);
          }
      };
      
      // schedule the first one.
      setTimeout(processVideo, 0);
      </script>
    <script type="text/javascript">
      let utils = new Utils('errorMessage');
      
      let streaming = false;
      let videoInput = document.getElementById('videoInput');
      let startAndStop = document.getElementById('startAndStop');
      let canvasOutput = document.getElementById('canvasOutput');
      let canvasContext = canvasOutput.getContext('2d');
      
      startAndStop.addEventListener('click', () => {
          if (!streaming) {
              //utils.clearError();
              utils.startCamera('qvga', onVideoStarted, 'videoInput');
          } else {
              utils.stopCamera();
              onVideoStopped();
          }
      });
      
      function onVideoStarted() {
          streaming = true;
          startAndStop.innerText = 'Stop';
          videoInput.width = videoInput.videoWidth;
          videoInput.height = videoInput.videoHeight;
          utils.executeCode('codeEditor');
      }
      
      function onVideoStopped() {
          streaming = false;
          canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
          startAndStop.innerText = 'Start';
      }
      
      utils.loadOpenCv(() => {
          startAndStop.removeAttribute('disabled');
      });
      </script>
  </body>
</html>